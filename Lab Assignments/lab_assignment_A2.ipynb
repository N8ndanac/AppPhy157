{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ST5d6dw3dLZh"
      },
      "source": [
        "# **AP157 Machine Learning Lab Assignment**\n",
        "## Module A.2: Classification -- Morphological Classification of Galaxies using Decision Trees\n",
        "\n",
        "_Instructions_: Answer each part of the assignment as completely as you can. Discuss **all** your code and results as clearly and concisely as possible.\n",
        "\n",
        "_Scoring Criteria_: 50% - *correctness of code*; 50% - *discussion of the code and results*. Maximum score is **100 points** (Parts 1, 2, and 3 are worth 20, 40, and 40 points, respectively).\n",
        "\n",
        "_Credits_: This assignment is based on the Week 6 module of the Coursera course \"Data-driven Astronomy\", \"Exploring machine learning classification\" ([link](https://www.coursera.org/learn/data-driven-astronomy/home/welcome))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZZaEzKHdVYG"
      },
      "source": [
        "### Student Information\n",
        "\n",
        "_Full Name (Last Name, First Name)_: \\ Danac, Nathan Gabriel C.\n",
        "_Student No._:\\ 2021-12517\n",
        "_Section_: THX-2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xv1STpPodaDL"
      },
      "source": [
        "### Submission Information\n",
        "\n",
        "_Date and Time Submitted (most recent upload)_:\n",
        "\n",
        "**HONOR PLEDGE** I affirm that I have upheld the highest principles of honesty and integrity in my academic work and that this lab assignment is my own work.\n",
        "\n",
        "**Sign here with your full name:** NATHAN GABRIEL C. DANAC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zw1kC_rdoHT"
      },
      "source": [
        "### Grading Information (c/o Instructor)\n",
        "\n",
        "TOTAL SCORE: **[]**/100\n",
        "\n",
        "Score breakdown:\n",
        "* Part 1 - []/20\n",
        "* Part 2 - []/40\n",
        "* Part 3 - []/40\n",
        "\n",
        "_Date and Time Scored (MM/DD/YYYY HH:MM AM/PM):_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNaYs-MfeDRl"
      },
      "source": [
        "For this assignment, you will work with galaxy data from the\n",
        "Sloan Digital Sky Survey (SDSS). First, you need to make a copy of the binary file ```galaxy_catalogue.npy``` and save it to a folder in your **own Google Drive**. This file is available from the AP157 Machine Learning Google Drive (under the Datasets folder).\n",
        "\n",
        "The code cells below will (1) mount your Google Drive and (2) load ```galaxy_catalogue.npy``` from your Google Drive folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee1mHlUWfcsc"
      },
      "source": [
        "Mount the Google Drive where you saved the .npy file.\n",
        "\n",
        "When you run this cell, you will be asked to sign in to your Google account and you will get an authorization code. Paste the code on the provided cell to mount the Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH0IOwb1YBHc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0C5c-8ofqDu"
      },
      "source": [
        "Run this command to list the directories in your Google Drive and check that the mount was successful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzKLlj20fsJu"
      },
      "source": [
        "!ls drive/My\\ Drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPLuh_jWfju8"
      },
      "source": [
        "Define the directory path to the location of the file, i.e. if it is in a\n",
        "folder named \"AP157\" under My Drive, then the file path will be \"/content/drive/My Drive/AP157\". Change the string variable in the code cell below, as needed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRpIuwdigDg5"
      },
      "source": [
        "file_path = \"/content/drive/My Drive/AP157/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VW7RFRGaik-6"
      },
      "source": [
        "Now, we can load the file using $\\tt numpy$'s $\\tt load$ function below.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y61tYmPIimUv"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "data = np.load(file_path + 'galaxy_catalogue.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpXP16UfWHQK"
      },
      "source": [
        "Print out the first couple of rows. Note that the columns are: $u-g$, $g-r$, $r-i$, $i-z$, eccentricity, $m_u$, $m_g$, $m_r$, $m_i$, $m_z$, $R_{50,u}$, $R_{50,r}$, $R_{50,z}$, $R_{90,u}$, $R_{90,r}$, $R_{90,z}$, and class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbQiDjyIWsjr"
      },
      "source": [
        "data[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eq2V7xzFtq7"
      },
      "source": [
        "#### PART 1 - Get features and targets *(20 pts.)*\n",
        "\n",
        "Write a function ```get_features_targets``` that splits the dataset into input features and their corresponding targets. In our case, the inputs are the 4 galaxy colors ($u-g$, $g-r$, $r-i$, and $i-z$), eccentricity, $ugriz$ magnitudes, and concentrations $R_{50}/R_{90}$ in the $u$, $r$, and $z$ bands. The targets are the classes.\n",
        "\n",
        "Here's an example of how your function should work:\n",
        "```\n",
        ">>> features, targets = get_features_targets(data)\n",
        ">>> print(\"Features shape:\", features.shape\n",
        ">>> print(\"Targets shape:\", targets.shape)\n",
        "Features shape: (780, 13)\n",
        "Targets shape: (780,)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfMtufdukBnu"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(data).to_numpy()\n",
        "\n",
        "def get_features_targets(dat):\n",
        "  ug, gr, ri, iz, ecc, m4u, m4g, m4r, m4i, m4z, pR50u, pR50r, pR50z, pR90u, pR90r, pR90z, c = dat.T\n",
        "  f = np.array([ug, gr, ri, iz, ecc, m4u, m4g, m4r, m4i, m4z, (pR50u/pR90u), (pR50r/pR90r), (pR50z/pR90z)]).T\n",
        "\n",
        "  return f, c\n",
        "\n",
        "features, targets = get_features_targets(df)\n",
        "print(features.shape)\n",
        "print(targets.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnePPYpJNWoY"
      },
      "source": [
        "#### PART 2 - Train and run a decision tree model *(40 pts.)*\n",
        "\n",
        "Write a function ```predict_class``` that will train and validate a model that predicts a galaxy's class from its photometric properties. In particular, it should do the following:\n",
        "1. Split the dataset into a training and test dataset using an 80:20 split.\n",
        "2. Train the input model using the training dataset features and targets.\n",
        "3. Return two arrays-- the predicted and actual class of the test galaxies.\n",
        "\n",
        "Here's an example of how your function should work:\n",
        "```\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "data = np.load(file_path + 'galaxy_catalogue.npy')\n",
        "predicted_class, actual_class = predict_class(data)\n",
        "\n",
        "for i in np.arange(3):\n",
        "   print(\"%d, %s, %s\" & (i, predicted_class[i], actual_class[i]))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "zrfpi9N6WSvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydeUh_Tzvf0n"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "def predict_class(dat):\n",
        "  f, t = get_features_targets(dat)\n",
        "\n",
        "  f_train, f_test, t_train, t_test, = train_test_split(f, t, test_size=0.2, train_size=0.8, random_state=99)\n",
        "  dcf = DecisionTreeClassifier(random_state=67).fit(f_train, t_train)\n",
        "\n",
        "  guess = dcf.predict(f_test)\n",
        "\n",
        "  return  guess, t_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class, actual_class = predict_class(df)\n",
        "\n",
        "for i in np.arange(50):\n",
        "   print(\"%d, %s, %s\" % (i, predicted_class[i], actual_class[i]))"
      ],
      "metadata": {
        "id": "Ug6VWlLeSroG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlSp5k92OjuM"
      },
      "source": [
        "#### PART 3 - Confusion matrix and accuracy *(40 pts.)*\n",
        "\n",
        "1. Get the confusion matrix for your test dataset-- this is a 3 x 3 matrix with the counts for each combination of actual and predicted class. *(25 pts.)*\n",
        "\n",
        "2. Get the test accuracy of your decision tree classifer, defined as the number of correct predictions divided by the total number of predictions. *(15 pts.)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZXvnOSLdH_k"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "\n",
        "cm = confusion_matrix(actual_class, predicted_class)\n",
        "#sn.heatmap(cm, annot=True, annot_kws={\"size\": 16}, xticklabels=[\"merger\", \"elliptical\", \"spiral\"], yticklabels=[\"merger\", \"elliptical\", \"spiral\"])\n",
        "\n",
        "map = ConfusionMatrixDisplay(cm, display_labels=[\"elliptical\", \"merger\", \"spiral\"])\n",
        "\n",
        "map.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(targets)\n",
        "cm"
      ],
      "metadata": {
        "id": "m8qEIunMEaAR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}